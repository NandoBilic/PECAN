{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16859f2e-22df-4aea-87a5-732e83fd0ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# one generator per radius, 2 048 bits each\n",
    "GEN0 = AllChem.GetMorganGenerator(radius=0, fpSize=2048)\n",
    "GEN1 = AllChem.GetMorganGenerator(radius=1, fpSize=2048)\n",
    "GEN2 = AllChem.GetMorganGenerator(radius=2, fpSize=2048)\n",
    "\n",
    "def fp6144_from_smiles(smiles):\n",
    "    \"\"\"Return torch.float32 tensor (6144,) or None if SMILES fails.\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    fp0 = torch.tensor(list(GEN0.GetFingerprint(mol)), dtype=torch.float32)\n",
    "    fp1 = torch.tensor(list(GEN1.GetFingerprint(mol)), dtype=torch.float32)\n",
    "    fp2 = torch.tensor(list(GEN2.GetFingerprint(mol)), dtype=torch.float32)\n",
    "    return torch.cat([fp0, fp1, fp2])            # (6144,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8ce4c45-e2f8-4a0d-81d5-fe31a3c0811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class PotencyDataset(Dataset):\n",
    "    def __init__(self, directory):\n",
    "        self.records = []\n",
    "        for fname in os.listdir(directory):\n",
    "            if fname.endswith(\".json\"):\n",
    "                with open(os.path.join(directory, fname)) as f:\n",
    "                    rec = json.load(f)\n",
    "                self.records.append((rec[\"SMILES\"], rec[\"label\"]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        smiles, label = self.records[idx]\n",
    "        fp = fp6144_from_smiles(smiles)\n",
    "        while fp is None:                # rare bad SMILES → pick next\n",
    "            idx = (idx + 1) % len(self.records)\n",
    "            smiles, label = self.records[idx]\n",
    "            fp = fp6144_from_smiles(smiles)\n",
    "        return fp, torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d09242-5926-4e98-9039-b36e7e1a894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# ── build the Dataset objects ──────────────────────────────────────\n",
    "train_dataset = PotencyDataset(\"train\")\n",
    "val_dataset   = PotencyDataset(\"val\")\n",
    "\n",
    "# ── quick sanity-check of label balance ────────────────────────────\n",
    "def show_distribution(ds, name):\n",
    "    labels = []\n",
    "    for i in range(len(ds)):\n",
    "        _, lbl = ds[i]\n",
    "        labels.append(int(lbl))\n",
    "    print(f\"{name} label distribution →\", Counter(labels))\n",
    "\n",
    "show_distribution(train_dataset, \"Train\")\n",
    "show_distribution(val_dataset,   \"Val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55b30910-a7de-4908-8378-aa01600ba7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BaselineMLP(nn.Module):\n",
    "    def __init__(self, input_dim=6144, hidden_dim=256, num_classes=6):\n",
    "        super(BaselineMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, num_classes)  # 6 potency categories\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.output(x)  # raw scores (logits), handled by loss function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f721aafc-eb96-4111-ab41-3b5aa1d9c467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 789.2476 | Train Acc: 0.5396 | Val Acc: 0.5784\n",
      "Epoch 2/10 | Train Loss: 619.0749 | Train Acc: 0.6490 | Val Acc: 0.5916\n",
      "Epoch 3/10 | Train Loss: 488.4316 | Train Acc: 0.7270 | Val Acc: 0.6089\n",
      "Epoch 4/10 | Train Loss: 365.3936 | Train Acc: 0.8018 | Val Acc: 0.6019\n",
      "Epoch 5/10 | Train Loss: 268.6252 | Train Acc: 0.8579 | Val Acc: 0.6003\n",
      "Epoch 6/10 | Train Loss: 203.0157 | Train Acc: 0.8939 | Val Acc: 0.6051\n",
      "Epoch 7/10 | Train Loss: 159.9796 | Train Acc: 0.9160 | Val Acc: 0.6046\n",
      "Epoch 8/10 | Train Loss: 129.2077 | Train Acc: 0.9340 | Val Acc: 0.5981\n",
      "Epoch 9/10 | Train Loss: 109.2569 | Train Acc: 0.9445 | Val Acc: 0.5943\n",
      "Epoch 10/10 | Train Loss: 95.6513 | Train Acc: 0.9513 | Val Acc: 0.6001\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from rdkit import RDLogger\n",
    "\n",
    "# Hide all RDKit warnings (keep “error” if you still want fatal messages)\n",
    "RDLogger.DisableLog(\"rdApp.*\")     # most common choice\n",
    "# RDLogger.DisableLog(\"rdApp.*\")         # silence everything\n",
    "\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = PotencyDataset(\"train\")\n",
    "val_dataset = PotencyDataset(\"val\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "model = BaselineMLP()\n",
    "criterion = nn.CrossEntropyLoss()  # for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    for batch in train_loader:\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    train_acc = (torch.tensor(all_preds) == torch.tensor(all_labels)).float().mean().item()\n",
    "\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            all_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_acc = (torch.tensor(all_preds) == torch.tensor(all_labels)).float().mean().item()\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {total_loss:.4f} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15bfb3ad-3466-466e-981a-71e80eb0308f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.BaselineMLP'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ddaf8452-a2f3-4f3a-b005-0ffcebffcae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted potency classes: [1]\n"
     ]
    }
   ],
   "source": [
    "#TESTING MINGS SMILES String Example\n",
    "#\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "from rdkit.DataStructs import ConvertToNumpyArray\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Prepare SMILES and molecule\n",
    "smiles = \"CC(C)c1c(O)c(O)c(C=O)c2c1cc(C)c(c2O)-c(c3O)c(C)cc4c3c(C=O)c(O)c(O)c4C(C)C\"\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "mol = Chem.AddHs(mol)\n",
    "\n",
    "# Generate 6144-bit Morgan fingerprint\n",
    "fp = []\n",
    "for radius in [0, 1, 2]:\n",
    "    bitvec = AllChem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=2048)\n",
    "    arr = np.zeros((2048,), dtype=int)\n",
    "    ConvertToNumpyArray(bitvec, arr)\n",
    "    fp.append(arr)\n",
    "fingerprint_6144 = np.concatenate(fp)\n",
    "\n",
    "# Convert to tensor and move to model's device\n",
    "x = torch.tensor(fingerprint_6144, dtype=torch.float32).unsqueeze(0)  # Add batch dim\n",
    "device = next(model.parameters()).device\n",
    "x = x.to(device)\n",
    "\n",
    "# Predict\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(x)\n",
    "\n",
    "# If your model returns multiple outputs (one per cell line):\n",
    "if isinstance(logits, list) or isinstance(logits, tuple):\n",
    "    probs = [F.softmax(head, dim=1) for head in logits]\n",
    "    preds = [torch.argmax(p, dim=1).item() for p in probs]\n",
    "else:\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    preds = torch.argmax(probs, dim=1).tolist()\n",
    "\n",
    "print(\"Predicted potency classes:\", preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6247f48b-8774-4403-9b61-adff2b0f3ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
