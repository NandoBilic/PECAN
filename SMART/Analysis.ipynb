{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9401f4e7-1cbd-4968-b077-49779b021023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: single-number accuracy on a loader\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total   = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = model(x).argmax(2)\n",
    "            mask  = y != -1\n",
    "            correct += ((preds == y) & mask).sum().item()\n",
    "            total   += mask.sum().item()\n",
    "    return correct / total if total > 0 else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03934edf-8157-43e4-93bb-c9ad7cf61e47",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MultiLineMLP:\n\tMissing key(s) in state_dict: \"bn_in.weight\", \"bn_in.bias\", \"bn_in.running_mean\", \"bn_in.running_var\", \"shared.0.weight\", \"shared.0.bias\", \"shared.1.weight\", \"shared.1.bias\", \"shared.1.running_mean\", \"shared.1.running_var\", \"shared.4.weight\", \"shared.4.bias\", \"shared.5.weight\", \"shared.5.bias\", \"shared.5.running_mean\", \"shared.5.running_var\", \"shared.8.weight\", \"shared.8.bias\", \"shared.9.weight\", \"shared.9.bias\", \"shared.9.running_mean\", \"shared.9.running_var\", \"shared.12.weight\", \"shared.12.bias\", \"shared.13.weight\", \"shared.13.bias\", \"shared.13.running_mean\", \"shared.13.running_var\", \"shared.16.weight\", \"shared.16.bias\", \"shared.17.weight\", \"shared.17.bias\", \"shared.17.running_mean\", \"shared.17.running_var\", \"classifier.weight\", \"classifier.bias\". \n\tUnexpected key(s) in state_dict: \"epoch\", \"model_state_dict\", \"optimizer_state_dict\", \"history\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_resampled.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m        \u001b[38;5;66;03m# choose file\u001b[39;00m\n\u001b[1;32m     21\u001b[0m model     \u001b[38;5;241m=\u001b[39m MultiLineMLP()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded\u001b[39m\u001b[38;5;124m\"\u001b[39m, ckpt_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/Nandos/lib/python3.9/site-packages/torch/nn/modules/module.py:2189\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2184\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2185\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2186\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2190\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MultiLineMLP:\n\tMissing key(s) in state_dict: \"bn_in.weight\", \"bn_in.bias\", \"bn_in.running_mean\", \"bn_in.running_var\", \"shared.0.weight\", \"shared.0.bias\", \"shared.1.weight\", \"shared.1.bias\", \"shared.1.running_mean\", \"shared.1.running_var\", \"shared.4.weight\", \"shared.4.bias\", \"shared.5.weight\", \"shared.5.bias\", \"shared.5.running_mean\", \"shared.5.running_var\", \"shared.8.weight\", \"shared.8.bias\", \"shared.9.weight\", \"shared.9.bias\", \"shared.9.running_mean\", \"shared.9.running_var\", \"shared.12.weight\", \"shared.12.bias\", \"shared.13.weight\", \"shared.13.bias\", \"shared.13.running_mean\", \"shared.13.running_var\", \"shared.16.weight\", \"shared.16.bias\", \"shared.17.weight\", \"shared.17.bias\", \"shared.17.running_mean\", \"shared.17.running_var\", \"classifier.weight\", \"classifier.bias\". \n\tUnexpected key(s) in state_dict: \"epoch\", \"model_state_dict\", \"optimizer_state_dict\", \"history\". "
     ]
    }
   ],
   "source": [
    "import torch, numpy as np, matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "\n",
    "class MultiLineMLP(nn.Module):\n",
    "    def __init__(self, input_dim=6144, hidden_dims=[1024,1024,512,512,256],\n",
    "                 num_lines=60, num_classes=6, p_drop=0.3):\n",
    "        super().__init__()\n",
    "        self.bn_in = nn.BatchNorm1d(input_dim)\n",
    "        layers, dims = [], [input_dim]+hidden_dims\n",
    "        for a,b in zip(dims,dims[1:]):\n",
    "            layers += [nn.Linear(a,b), nn.BatchNorm1d(b), nn.ReLU(), nn.Dropout(p_drop)]\n",
    "        self.shared = nn.Sequential(*layers)\n",
    "        self.classifier = nn.Linear(hidden_dims[-1], num_lines*num_classes)\n",
    "    def forward(self,x):\n",
    "        x = self.bn_in(x)\n",
    "        x = self.shared(x)\n",
    "        return self.classifier(x).view(x.size(0),-1,6)\n",
    "\n",
    "device    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ckpt_path = \"best_resampled.pt\"        # choose file\n",
    "model     = MultiLineMLP().to(device)\n",
    "model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "model.eval()\n",
    "print(\"Loaded\", ckpt_path)\n",
    "\n",
    "# define evaluate(), macro_precision_recall() here or import them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac4245-29b3-40b1-94fe-84cadec6dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Post‑training Analysis Helpers (for paper‑style figures)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## 11a. Training curves (stored during loop)\n",
    "# Make sure train_loss_hist and val_acc_hist were populated above\n",
    "# If not, uncomment these two lists at the very top of the loop:\n",
    "# train_loss_hist, val_acc_hist = [], []\n",
    "# inside epoch loop: train_loss_hist.append(avg_loss); val_acc_hist.append(val_acc)\n",
    "\n",
    "if 'train_loss_hist' in globals() and 'val_acc_hist' in globals():\n",
    "    epochs = range(1, len(train_loss_hist)+1)\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(epochs, train_loss_hist, label='Train Loss')\n",
    "    ax1.set_xlabel('Epoch'); ax1.set_ylabel('Loss')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(epochs, val_acc_hist, color='tab:red', label='Val Acc')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    fig.legend(loc='upper right'); plt.title('Training vs Validation'); plt.show()\n",
    "else:\n",
    "    print('Run training loop with train_loss_hist / val_acc_hist lists to get curve plot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0d372d-a467-4805-abf0-c4f2cc58f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 11b. Table‑2 Precision/Recall (macro within‑one)\n",
    "prec, rec = macro_precision_recall(model, val_loader, device)\n",
    "print(\"\n",
    "Table 2 – Precision & Recall (Exact / ±1)\")\n",
    "print(\"Class  ExactP  ±1P  ExactR  ±1R\")\n",
    "for c in range(6):\n",
    "    print(f\"  {c}    {prec[c,0]:.3f}  {prec[c,1]:.3f}  {rec[c,0]:.3f}  {rec[c,1]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e9a59-ea4b-48f4-873b-bce9ebd56163",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 11c. Figure‑1 distribution of activity levels\n",
    "true_cnt = np.zeros(6, dtype=int)\n",
    "pred_cnt = np.zeros(6, dtype=int)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x, y in val_loader:\n",
    "        x = x.to(device)\n",
    "        p = model(x).argmax(2).cpu().numpy(); y = y.numpy()\n",
    "        m = y != -1\n",
    "        for c in range(6):\n",
    "            true_cnt[c] += ((y==c)&m).sum()\n",
    "            pred_cnt[c] += ((p==c)&m).sum()\n",
    "levels = ['Inactive','Weak','Mild','Active','Potent','Super']\n",
    "idx = np.arange(6)\n",
    "plt.figure();\n",
    "plt.bar(idx-0.2, pred_cnt, width=0.4, label='Predicted')\n",
    "plt.bar(idx+0.2, true_cnt, width=0.4, label='True')\n",
    "plt.xticks(idx, levels, rotation=45); plt.ylabel('Count');\n",
    "plt.title('Figure 1 – Activity‑level distribution (Val set)'); plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292a5ce7-9c6c-4898-84a6-3203104c38a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
