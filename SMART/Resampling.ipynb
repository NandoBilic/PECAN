{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e981c014-0a0b-47a8-8d4a-dbfdddd174a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 46663 records to train_resampled.jsonl.gz\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import gzip, json, random\n",
    "from collections import Counter\n",
    "\n",
    "def resample_jsonl(input_path, output_path, seed=42):\n",
    "    random.seed(seed)\n",
    "    records = []\n",
    "    with gzip.open(input_path, \"rt\") as f:\n",
    "        for line in f:\n",
    "            records.append(json.loads(line))\n",
    "    N = len(records)\n",
    "\n",
    "    total_counts = Counter()\n",
    "    for rec in records:\n",
    "        for lbl in rec[\"label_vector\"]:\n",
    "            if lbl != -1:\n",
    "                total_counts[lbl] += 1\n",
    "\n",
    "    total_pairs = sum(total_counts.values())\n",
    "    class_weights = {\n",
    "        c: (total_pairs / 6) / total_counts[c]\n",
    "        for c in range(6)\n",
    "    }\n",
    "\n",
    "    sample_weights = []\n",
    "    for rec in records:\n",
    "        w = [\n",
    "            class_weights[lbl]\n",
    "            for lbl in rec[\"label_vector\"]\n",
    "            if lbl != -1\n",
    "        ]\n",
    "        sample_weights.append(sum(w) / len(w))\n",
    "\n",
    "    # Normalize to sum to 1\n",
    "    tot = sum(sample_weights)\n",
    "    sample_weights = [w / tot for w in sample_weights]\n",
    "\n",
    " \n",
    "    indices = random.choices(range(N), weights=sample_weights, k=N)\n",
    "\n",
    "    # --- 6. Write out the new balanced JSONL ---\n",
    "    with gzip.open(output_path, \"wt\") as out_f:\n",
    "        for i in indices:\n",
    "            out_f.write(json.dumps(records[i]) + \"\\n\")\n",
    "    print(f\"Wrote {len(indices)} records to {output_path}\")\n",
    "\n",
    "resample_jsonl(\"train.jsonl.gz\", \"train_resampled.jsonl.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e7a242a-c75d-4f36-b800-b3b3e9c2bb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | TL 1.173 | VL 1.242 | Acc 0.4958 | LR 5.0e-04\n",
      "   ✓ New best accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | TL 1.021 | VL 1.341 | Acc 0.4910 | LR 5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | TL 0.948 | VL 1.347 | Acc 0.4965 | LR 5.0e-04\n",
      "   ✓ New best accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | TL 0.896 | VL 1.345 | Acc 0.5112 | LR 2.5e-04\n",
      "   ✓ New best accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | TL 0.800 | VL 1.437 | Acc 0.5145 | LR 2.5e-04\n",
      "   ✓ New best accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | TL 0.756 | VL 1.397 | Acc 0.5063 | LR 2.5e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | TL 0.728 | VL 1.548 | Acc 0.4974 | LR 1.3e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | TL 0.674 | VL 1.430 | Acc 0.5185 | LR 1.3e-04\n",
      "   ✓ New best accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | TL 0.647 | VL 1.553 | Acc 0.5151 | LR 1.3e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | TL 0.637 | VL 1.454 | Acc 0.5328 | LR 6.3e-05\n",
      "   ✓ New best accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | TL 0.609 | VL 1.530 | Acc 0.5284 | LR 6.3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | TL 0.597 | VL 1.518 | Acc 0.5247 | LR 6.3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | TL 0.589 | VL 1.567 | Acc 0.5246 | LR 3.1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | TL 0.578 | VL 1.437 | Acc 0.5338 | LR 3.1e-05\n",
      "   ✓ New best accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | TL 0.574 | VL 1.480 | Acc 0.5320 | LR 3.1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | TL 0.569 | VL 1.495 | Acc 0.5265 | LR 1.6e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | TL 0.566 | VL 1.515 | Acc 0.5291 | LR 1.6e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | TL 0.559 | VL 1.525 | Acc 0.5323 | LR 1.6e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | TL 0.560 | VL 1.513 | Acc 0.5294 | LR 7.8e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | TL 0.556 | VL 1.512 | Acc 0.5370 | LR 7.8e-06\n",
      "   ✓ New best accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | TL 0.555 | VL 1.471 | Acc 0.5365 | LR 7.8e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | TL 0.555 | VL 1.493 | Acc 0.5324 | LR 3.9e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | TL 0.552 | VL 1.476 | Acc 0.5357 | LR 3.9e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | TL 0.551 | VL 1.540 | Acc 0.5253 | LR 3.9e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | TL 0.552 | VL 1.502 | Acc 0.5257 | LR 2.0e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | TL 0.550 | VL 1.492 | Acc 0.5326 | LR 2.0e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | TL 0.549 | VL 1.490 | Acc 0.5369 | LR 2.0e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | TL 0.550 | VL 1.429 | Acc 0.5446 | LR 9.8e-07\n",
      "   ✓ New best accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | TL 0.548 | VL 1.453 | Acc 0.5397 | LR 9.8e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | TL 0.550 | VL 1.398 | Acc 0.5406 | LR 9.8e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | TL 0.549 | VL 1.480 | Acc 0.5372 | LR 4.9e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | TL 0.551 | VL 1.507 | Acc 0.5349 | LR 4.9e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | TL 0.549 | VL 1.489 | Acc 0.5372 | LR 4.9e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | TL 0.550 | VL 1.481 | Acc 0.5376 | LR 2.4e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | TL 0.549 | VL 1.519 | Acc 0.5360 | LR 2.4e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | TL 0.551 | VL 1.477 | Acc 0.5351 | LR 2.4e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | TL 0.549 | VL 1.461 | Acc 0.5333 | LR 1.2e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | TL 0.549 | VL 1.458 | Acc 0.5371 | LR 1.2e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | TL 0.550 | VL 1.561 | Acc 0.5337 | LR 1.2e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | TL 0.548 | VL 1.526 | Acc 0.5338 | LR 6.1e-08\n",
      "Finished. Best validation accuracy: 0.5446336553684783\n",
      "Table 2 saved to table2_metrics.csv / table2.tex; curves + Figure 1 saved in plots\n"
     ]
    }
   ],
   "source": [
    "#MODIFICATION OF CELL BELOW DELETE NEXT CELL IF WORKS\n",
    "import gzip, json, torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from rdkit import RDLogger\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "# ---------- Silence RDKit chatter ----------\n",
    "RDLogger.DisableLog(\"rdApp.*\")\n",
    "\n",
    "\n",
    "class JSONLPotencyDataset(Dataset):\n",
    "    def __init__(self, path_to_jsonl_gz):\n",
    "        self.records = []\n",
    "        with gzip.open(path_to_jsonl_gz, \"rt\") as f:\n",
    "            for line in f:\n",
    "                rec = json.loads(line)\n",
    "                self.records.append((rec[\"smiles\"], rec[\"label_vector\"]))\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "    def __getitem__(self, idx):\n",
    "        smiles, label_vec = self.records[idx]\n",
    "        fp = fp6144_from_smiles(smiles)\n",
    "        while fp is None:  # skip invalid SMILES\n",
    "            idx = (idx + 1) % len(self.records)\n",
    "            smiles, label_vec = self.records[idx]\n",
    "            fp = fp6144_from_smiles(smiles)\n",
    "        return fp, torch.tensor(label_vec, dtype=torch.long)\n",
    "\n",
    "GEN0 = AllChem.GetMorganGenerator(radius=0, fpSize=2048)\n",
    "GEN1 = AllChem.GetMorganGenerator(radius=1, fpSize=2048)\n",
    "GEN2 = AllChem.GetMorganGenerator(radius=2, fpSize=2048)\n",
    "\n",
    "def fp6144_from_smiles(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    fp0 = torch.tensor(list(GEN0.GetFingerprint(mol)), dtype=torch.float32)\n",
    "    fp1 = torch.tensor(list(GEN1.GetFingerprint(mol)), dtype=torch.float32)\n",
    "    fp2 = torch.tensor(list(GEN2.GetFingerprint(mol)), dtype=torch.float32)\n",
    "    return torch.cat([fp0, fp1, fp2])  # (6144,)\n",
    "\n",
    "def full_val_accuracy(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = np.zeros(60); total = np.zeros(60)\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x).argmax(2)\n",
    "            mask = y != -1\n",
    "            correct += ((pred == y) & mask).sum(0).cpu().numpy()\n",
    "            total   += mask.sum(0).cpu().numpy()\n",
    "    accs = [c / t if t>0 else 0.0 for c, t in zip(correct, total)]\n",
    "    return float(np.nanmean(accs)), accs\n",
    "\n",
    "class MultiLineMLP5(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim=6144,\n",
    "                 hidden_dims=[1024, 1024, 512, 512, 256],\n",
    "                 num_lines=60,\n",
    "                 num_classes=6,\n",
    "                 p_drop=0.3):\n",
    "        super().__init__()\n",
    "        self.bn_in = nn.BatchNorm1d(input_dim)\n",
    "        layers = []\n",
    "        dims = [input_dim] + hidden_dims\n",
    "        for d_in, d_out in zip(dims[:-1], dims[1:]):\n",
    "            layers += [\n",
    "                nn.Linear(d_in, d_out),\n",
    "                nn.BatchNorm1d(d_out),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p_drop),\n",
    "            ]\n",
    "        self.shared = nn.Sequential(*layers)\n",
    "        self.classifier = nn.Linear(hidden_dims[-1], num_lines * num_classes)\n",
    "    def forward(self, x):\n",
    "        x = self.bn_in(x)\n",
    "        feat = self.shared(x)\n",
    "        logits = self.classifier(feat)\n",
    "        return logits.view(-1, 60, 6)\n",
    "\n",
    "train_ds = JSONLPotencyDataset(\"train.jsonl.gz\")\n",
    "val_ds   = JSONLPotencyDataset(\"val.jsonl.gz\")\n",
    "test_ds  = JSONLPotencyDataset(\"test.jsonl.gz\")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model  = MultiLineMLP5().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2)\n",
    "\n",
    "\n",
    "def full_metrics(model, loader, device):\n",
    "    \"\"\"Return per‑line precision, recall, accuracy and support.\"\"\"\n",
    "    model.eval()\n",
    "    tp = np.zeros(60); fp = np.zeros(60); fn = np.zeros(60)\n",
    "    correct = np.zeros(60); total = np.zeros(60)\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x).argmax(2)\n",
    "            mask = y != -1\n",
    "            for line in range(60):\n",
    "                m = mask[:, line]\n",
    "                if m.sum() == 0:\n",
    "                    continue\n",
    "                p = pred[m, line].cpu().numpy()\n",
    "                t = y[m, line].cpu().numpy()\n",
    "                correct[line] += (p == t).sum()\n",
    "                total[line]   += len(t)\n",
    "                for cls in range(6):\n",
    "                    tp[line] += ((p == cls) & (t == cls)).sum()\n",
    "                    fp[line] += ((p == cls) & (t != cls)).sum()\n",
    "                    fn[line] += ((p != cls) & (t == cls)).sum()\n",
    "    acc  = np.divide(correct, total, out=np.zeros_like(correct), where=total>0)\n",
    "    prec = np.divide(tp, tp + fp + 1e-9)\n",
    "    rec  = np.divide(tp, tp + fn + 1e-9)\n",
    "    return acc, prec, rec, total\n",
    "\n",
    "history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "plots_dir = Path(\"plots\"); plots_dir.mkdir(exist_ok=True)\n",
    "\n",
    "best_acc = 0.0\n",
    "for epoch in range(1, 41):\n",
    "    # ----- Train -----\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch}\", leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits.view(-1, 6), y.view(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # ----- Validation -----\n",
    "    model.eval(); val_running = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            val_running += criterion(model(x).view(-1, 6), y.view(-1)).item()\n",
    "    val_loss = val_running / len(val_loader)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Accuracy\n",
    "    acc_avg, _ = full_val_accuracy(model, val_loader, device)\n",
    "\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    history[\"val_acc\"].append(acc_avg)\n",
    "\n",
    "    print(f\"Epoch {epoch:02} | TL {train_loss:.3f} | VL {val_loss:.3f} | Acc {acc_avg:.4f} | LR {optimizer.param_groups[0]['lr']:.1e}\")\n",
    "\n",
    "    if acc_avg > best_acc:\n",
    "        best_acc = acc_avg\n",
    "        torch.save({\"epoch\": epoch, \"model_state_dict\": model.state_dict(), \"optimizer_state_dict\": optimizer.state_dict(), \"history\": history}, \"best_resampled.pt\")\n",
    "        print(\"   ✓ New best accuracy\")\n",
    "\n",
    "# ---------- Curves ----------\n",
    "plt.figure();\n",
    "plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend(); plt.tight_layout()\n",
    "plt.savefig(plots_dir/\"loss_curve.png\", dpi=120)\n",
    "plt.close()\n",
    "\n",
    "plt.figure();\n",
    "plt.plot(history[\"val_acc\"], label=\"Val Accuracy\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\")\n",
    "plt.tight_layout(); plt.savefig(plots_dir/\"accuracy_curve.png\", dpi=120); plt.close()\n",
    "\n",
    "# ---------- Test‑set metrics (Table 2 + Figure 1) ----------\n",
    "acc, prec, rec, support = full_metrics(model, test_loader, device)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"CellLine\": np.arange(60),\n",
    "    \"Precision\": prec,\n",
    "    \"Recall\": rec,\n",
    "    \"Accuracy\": acc,\n",
    "    \"Support\": support,\n",
    "})\n",
    "\n",
    "df.to_csv(\"table2_metrics.csv\", index=False)\n",
    "df.to_latex(\"table2.tex\", index=False, float_format=\"%.3f\")\n",
    "\n",
    "plt.figure();\n",
    "plt.scatter(rec, prec)\n",
    "for i, (x, y) in enumerate(zip(rec, prec)):\n",
    "    plt.annotate(str(i), (x, y), fontsize=6, alpha=0.7)\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision vs Recall per Cell Line\")\n",
    "plt.tight_layout(); plt.savefig(plots_dir/\"precision_recall_scatter.png\", dpi=120); plt.close()\n",
    "\n",
    "print(\"Finished. Best validation accuracy:\", best_acc)\n",
    "print(\"Table 2 saved to table2_metrics.csv / table2.tex; curves + Figure 1 saved in\", plots_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d0e74c1-71e2-40ff-91b8-fdb271c8bf90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss 910.9 | Val Loss 168.1 | Acc 0.4055 | LR 5.0e-04\n",
      "  ✓ New best: 0.4055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train Loss 729.6 | Val Loss 161.8 | Acc 0.4362 | LR 5.0e-04\n",
      "  ✓ New best: 0.4362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Train Loss 660.5 | Val Loss 165.4 | Acc 0.4447 | LR 5.0e-04\n",
      "  ✓ New best: 0.4447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Train Loss 616.2 | Val Loss 154.2 | Acc 0.4580 | LR 5.0e-04\n",
      "  ✓ New best: 0.4580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train Loss 581.0 | Val Loss 152.6 | Acc 0.4620 | LR 5.0e-04\n",
      "  ✓ New best: 0.4620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Train Loss 557.6 | Val Loss 156.5 | Acc 0.4664 | LR 5.0e-04\n",
      "  ✓ New best: 0.4664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Train Loss 540.2 | Val Loss 149.2 | Acc 0.4782 | LR 5.0e-04\n",
      "  ✓ New best: 0.4782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Train Loss 524.8 | Val Loss 156.2 | Acc 0.4632 | LR 5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Train Loss 514.6 | Val Loss 138.2 | Acc 0.4891 | LR 5.0e-04\n",
      "  ✓ New best: 0.4891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss 507.0 | Val Loss 140.5 | Acc 0.4876 | LR 5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss 497.5 | Val Loss 141.1 | Acc 0.4879 | LR 5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss 491.3 | Val Loss 132.2 | Acc 0.5022 | LR 5.0e-04\n",
      "  ✓ New best: 0.5022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss 488.1 | Val Loss 133.3 | Acc 0.5010 | LR 5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss 482.4 | Val Loss 134.9 | Acc 0.4934 | LR 5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss 479.6 | Val Loss 131.6 | Acc 0.5056 | LR 5.0e-04\n",
      "  ✓ New best: 0.5056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss 472.1 | Val Loss 137.3 | Acc 0.4928 | LR 5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss 472.5 | Val Loss 138.9 | Acc 0.4931 | LR 5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss 469.0 | Val Loss 132.4 | Acc 0.5075 | LR 2.5e-04\n",
      "  ✓ New best: 0.5075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss 440.9 | Val Loss 131.5 | Acc 0.5048 | LR 2.5e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss 423.8 | Val Loss 133.0 | Acc 0.5107 | LR 2.5e-04\n",
      "  ✓ New best: 0.5107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss 420.5 | Val Loss 128.1 | Acc 0.5172 | LR 2.5e-04\n",
      "  ✓ New best: 0.5172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss 419.2 | Val Loss 130.4 | Acc 0.5203 | LR 2.5e-04\n",
      "  ✓ New best: 0.5203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss 416.6 | Val Loss 134.7 | Acc 0.5105 | LR 2.5e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss 412.6 | Val Loss 134.2 | Acc 0.5189 | LR 1.3e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss 402.4 | Val Loss 132.3 | Acc 0.5225 | LR 1.3e-04\n",
      "  ✓ New best: 0.5225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss 394.3 | Val Loss 132.5 | Acc 0.5192 | LR 1.3e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss 390.4 | Val Loss 127.8 | Acc 0.5269 | LR 1.3e-04\n",
      "  ✓ New best: 0.5269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss 389.4 | Val Loss 132.6 | Acc 0.5277 | LR 1.3e-04\n",
      "  ✓ New best: 0.5277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss 386.1 | Val Loss 133.4 | Acc 0.5207 | LR 1.3e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss 385.6 | Val Loss 126.2 | Acc 0.5307 | LR 1.3e-04\n",
      "  ✓ New best: 0.5307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Loss 382.7 | Val Loss 128.0 | Acc 0.5269 | LR 1.3e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train Loss 380.5 | Val Loss 125.4 | Acc 0.5366 | LR 1.3e-04\n",
      "  ✓ New best: 0.5366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Train Loss 378.9 | Val Loss 130.7 | Acc 0.5289 | LR 1.3e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Train Loss 378.7 | Val Loss 130.5 | Acc 0.5284 | LR 1.3e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Train Loss 377.0 | Val Loss 134.0 | Acc 0.5312 | LR 6.3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Train Loss 372.2 | Val Loss 127.5 | Acc 0.5376 | LR 6.3e-05\n",
      "  ✓ New best: 0.5376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Train Loss 368.2 | Val Loss 125.1 | Acc 0.5377 | LR 6.3e-05\n",
      "  ✓ New best: 0.5377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Train Loss 366.5 | Val Loss 127.7 | Acc 0.5340 | LR 6.3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Train Loss 364.9 | Val Loss 129.8 | Acc 0.5335 | LR 6.3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Train Loss 364.6 | Val Loss 127.8 | Acc 0.5364 | LR 3.1e-05\n",
      "Training complete. Best Avg Val Acc = 0.5377233967144139\n"
     ]
    }
   ],
   "source": [
    "import gzip, json, torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from rdkit import RDLogger\n",
    "\n",
    "# Silence RDKit chatter\n",
    "RDLogger.DisableLog(\"rdApp.*\")\n",
    "\n",
    "# --- Dataset class (unchanged) ---\n",
    "class JSONLPotencyDataset(Dataset):\n",
    "    def __init__(self, path_to_jsonl_gz):\n",
    "        self.records = []\n",
    "        with gzip.open(path_to_jsonl_gz, \"rt\") as f:\n",
    "            for line in f:\n",
    "                rec = json.loads(line)\n",
    "                self.records.append((rec[\"smiles\"], rec[\"label_vector\"]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        smiles, label_vec = self.records[idx]\n",
    "        fp = fp6144_from_smiles(smiles)\n",
    "        while fp is None:\n",
    "            idx = (idx + 1) % len(self.records)\n",
    "            smiles, label_vec = self.records[idx]\n",
    "            fp = fp6144_from_smiles(smiles)\n",
    "        return fp, torch.tensor(label_vec, dtype=torch.long)\n",
    "\n",
    "# --- Fingerprint helper (unchanged) ---\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "GEN0 = AllChem.GetMorganGenerator(radius=0, fpSize=2048)\n",
    "GEN1 = AllChem.GetMorganGenerator(radius=1, fpSize=2048)\n",
    "GEN2 = AllChem.GetMorganGenerator(radius=2, fpSize=2048)\n",
    "\n",
    "def fp6144_from_smiles(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    fp0 = torch.tensor(list(GEN0.GetFingerprint(mol)), dtype=torch.float32)\n",
    "    fp1 = torch.tensor(list(GEN1.GetFingerprint(mol)), dtype=torch.float32)\n",
    "    fp2 = torch.tensor(list(GEN2.GetFingerprint(mol)), dtype=torch.float32)\n",
    "    return torch.cat([fp0, fp1, fp2])  # (6144,)\n",
    "\n",
    "# --- Model definition (same 5-layer MLP) ---\n",
    "class MultiLineMLP5(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim=6144,\n",
    "                 hidden_dims=[1024, 1024, 512, 512, 256],\n",
    "                 num_lines=60,\n",
    "                 num_classes=6,\n",
    "                 p_drop=0.3):\n",
    "        super().__init__()\n",
    "        self.bn_in = nn.BatchNorm1d(input_dim)\n",
    "        layers = []\n",
    "        dims = [input_dim] + hidden_dims\n",
    "        for d_in, d_out in zip(dims[:-1], dims[1:]):\n",
    "            layers += [\n",
    "                nn.Linear(d_in, d_out),\n",
    "                nn.BatchNorm1d(d_out),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p_drop),\n",
    "            ]\n",
    "        self.shared = nn.Sequential(*layers)\n",
    "        self.classifier = nn.Linear(hidden_dims[-1], num_lines * num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn_in(x)\n",
    "        feat = self.shared(x)\n",
    "        logits = self.classifier(feat)\n",
    "        return logits.view(-1, 60, 6)\n",
    "        \n",
    "train_ds = JSONLPotencyDataset(\"train_resampled.jsonl.gz\")\n",
    "val_ds   = JSONLPotencyDataset(\"val.jsonl.gz\")\n",
    "test_ds  = JSONLPotencyDataset(\"test.jsonl.gz\")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64,\n",
    "                          shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=64,\n",
    "                          shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=64,\n",
    "                          shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# --- Training setup ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model  = MultiLineMLP5().to(device)\n",
    "\n",
    "# No class-weights here:\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=2)\n",
    "\n",
    "def full_val_accuracy(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = np.zeros(60); total = np.zeros(60)\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x).argmax(2)\n",
    "            mask = y != -1\n",
    "            correct += ((pred == y) & mask).sum(0).cpu().numpy()\n",
    "            total   += mask.sum(0).cpu().numpy()\n",
    "    accs = [c / t if t>0 else 0.0 for c, t in zip(correct, total)]\n",
    "    return float(np.nanmean(accs)), accs\n",
    "\n",
    "# --- Training loop ---\n",
    "best_acc = 0.0\n",
    "for epoch in range(1, 41):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch}\", leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits.view(-1,6), y.view(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # validation\n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            val_loss += criterion(\n",
    "                model(x).view(-1,6), y.view(-1)\n",
    "            ).item()\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "    avg_acc, _ = full_val_accuracy(model, val_loader, device)\n",
    "    print(f\"Epoch {epoch:02} | Train Loss {train_loss:.1f} \"\n",
    "          f\"| Val Loss {val_loss:.1f} | Acc {avg_acc:.4f} \"\n",
    "          f\"| LR {optimizer.param_groups[0]['lr']:.1e}\")\n",
    "\n",
    "    if avg_acc > best_acc:\n",
    "        best_acc = avg_acc\n",
    "        torch.save(model.state_dict(), \"best_resampled.pt\")\n",
    "        print(f\"  ✓ New best: {best_acc:.4f}\")\n",
    "\n",
    "print(\"Training complete. Best Avg Val Acc =\", best_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18d0fe34-5246-400d-95c5-7dc739eefa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Define the function (one cell)\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def compute_precision_recall(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            preds = model(x).argmax(dim=2)\n",
    "            mask = (y != -1)\n",
    "            all_preds.append( preds[mask].cpu().numpy().ravel() )\n",
    "            all_labels.append(y[mask].cpu().numpy().ravel())\n",
    "    y_pred = np.concatenate(all_preds)\n",
    "    y_true = np.concatenate(all_labels)\n",
    "    precision = np.zeros(6); recall = np.zeros(6)\n",
    "    for c in range(6):\n",
    "        tp = ((y_pred==c)&(y_true==c)).sum()\n",
    "        fp = ((y_pred==c)&(y_true!=c)).sum()\n",
    "        fn = ((y_pred!=c)&(y_true==c)).sum()\n",
    "        precision[c] = tp/(tp+fp) if tp+fp>0 else np.nan\n",
    "        recall[c]    = tp/(tp+fn) if tp+fn>0 else np.nan\n",
    "    return precision, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3be68e33-7790-4e43-9c59-a698ff34063f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0:  prec=0.770,  rec=0.473\n",
      "class 1:  prec=0.513,  rec=0.406\n",
      "class 2:  prec=0.494,  rec=0.357\n",
      "class 3:  prec=0.209,  rec=0.398\n",
      "class 4:  prec=0.088,  rec=0.469\n",
      "class 5:  prec=0.063,  rec=0.630\n"
     ]
    }
   ],
   "source": [
    "# 2) Call it in a fresh cell once training is done\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))  # if you restarted kernel\n",
    "model.to(device)\n",
    "\n",
    "precision, recall = compute_precision_recall(model, val_loader, device)\n",
    "for c in range(6):\n",
    "    print(f\"class {c}:  prec={precision[c]:.3f},  rec={recall[c]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "324dca82-c32a-4d29-ba6e-260a7a2744a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Class   Exact P      ±1 P   Exact R      ±1 R\n",
      "     0      76.3%      94.7%      46.7%      74.2%\n",
      "     1      51.0%      98.2%      40.3%      72.2%\n",
      "     2      49.7%      84.0%      35.8%      59.8%\n",
      "     3      21.1%      66.3%      40.2%      73.3%\n",
      "     4       8.9%      27.9%      47.3%      77.7%\n",
      "     5       6.5%      13.2%      61.6%      85.2%\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def macro_precision_recall(model, loader, device, num_lines=59):\n",
    "    \"\"\"\n",
    "    Returns two 2-D arrays of shape (6 classes, 2 metrics):\n",
    "        [exact , within-one] for precision and recall.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    # per-line confusion buckets\n",
    "    exact = defaultdict(lambda: np.zeros((6, 3), dtype=int))       # TP, FP, FN\n",
    "    within = defaultdict(lambda: np.zeros((6, 3), dtype=int))      # TPw, FPw, FNw\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:                         # y: (B, 60)\n",
    "            x = x.to(device)\n",
    "            logits = model(x)[:, :num_lines]        # (B, 59, 6)  drop 60th line\n",
    "            preds  = logits.argmax(2).cpu().numpy()\n",
    "            y      = y[:, :num_lines].cpu().numpy()\n",
    "            \n",
    "            for line_idx in range(num_lines):\n",
    "                true_line   = y[:, line_idx]\n",
    "                pred_line   = preds[:, line_idx]\n",
    "                mask        = true_line != -1\n",
    "                yt          = true_line[mask]\n",
    "                yp          = pred_line[mask]\n",
    "                if yt.size == 0:                    # line had no labels\n",
    "                    continue\n",
    "                \n",
    "                for c in range(6):\n",
    "                    tp = np.sum((yp == c) & (yt == c))\n",
    "                    fp = np.sum((yp == c) & (yt != c))\n",
    "                    fn = np.sum((yp != c) & (yt == c))\n",
    "                    exact[line_idx][c] += (tp, fp, fn)\n",
    "                    \n",
    "                    # within-one: hit if |pred-true| <= 1\n",
    "                    tp_w = np.sum((yp == c) & (np.abs(yt - c) <= 1))\n",
    "                    fp_w = np.sum((yp == c) & (np.abs(yt - c) >  1))\n",
    "                    fn_w = np.sum((yp != c) & (np.abs(yp - c) <= 1) & (yt == c))\n",
    "                    within[line_idx][c] += (tp_w, fp_w, fn_w)\n",
    "    \n",
    "    # macro-average over cell lines (skip lines with zero support)\n",
    "    prec = np.zeros((6, 2))\n",
    "    rec  = np.zeros((6, 2))\n",
    "    for c in range(6):\n",
    "        # gather per-line metrics then average\n",
    "        p_exact, r_exact, p_within, r_within = [], [], [], []\n",
    "        for line in exact.keys():\n",
    "            tp, fp, fn         = exact[line][c]\n",
    "            tpw, fpw, fnw      = within[line][c]\n",
    "            if tp + fn == 0:    # no true instances of class c in this line\n",
    "                continue\n",
    "            p_exact.append(  tp / (tp + fp) if tp+fp>0 else np.nan )\n",
    "            r_exact.append(  tp / (tp + fn)                 )\n",
    "            p_within.append( tpw / (tpw + fpw) if tpw+fpw>0 else np.nan )\n",
    "            r_within.append( tpw / (tpw + fnw)               )\n",
    "        prec[c, 0] = np.nanmean(p_exact)\n",
    "        prec[c, 1] = np.nanmean(p_within)\n",
    "        rec[c, 0]  = np.nanmean(r_exact)\n",
    "        rec[c, 1]  = np.nanmean(r_within)\n",
    "    return prec, rec\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Example usage on your validation set\n",
    "prec, rec = macro_precision_recall(model, val_loader, device)\n",
    "\n",
    "headers = [\"Exact P\", \"±1 P\", \"Exact R\", \"±1 R\"]\n",
    "print(f\"{'Class':>6}  {headers[0]:>8}  {headers[1]:>8}  \"\n",
    "      f\"{headers[2]:>8}  {headers[3]:>8}\")\n",
    "for c in range(6):\n",
    "    print(f\"{c:>6}  {prec[c,0]*100:8.1f}%  {prec[c,1]*100:8.1f}%  \"\n",
    "          f\"{rec[c,0]*100:8.1f}%  {rec[c,1]*100:8.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a68b0991-028b-48b7-8878-76068a78ee69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss 877.7 | Val Loss 185.0 | Acc 0.3957 | LR 5.0e-04\n",
      "  ✓ New best: 0.3957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train Loss 702.8 | Val Loss 186.3 | Acc 0.4179 | LR 5.0e-04\n",
      "  ✓ New best: 0.4179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Train Loss 639.8 | Val Loss 173.5 | Acc 0.4303 | LR 5.0e-04\n",
      "  ✓ New best: 0.4303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Train Loss 600.8 | Val Loss 163.0 | Acc 0.4524 | LR 5.0e-04\n",
      "  ✓ New best: 0.4524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train Loss 568.9 | Val Loss 158.9 | Acc 0.4540 | LR 5.0e-04\n",
      "  ✓ New best: 0.4540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Train Loss 549.8 | Val Loss 155.0 | Acc 0.4540 | LR 5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Train Loss 534.1 | Val Loss 158.2 | Acc 0.4586 | LR 5.0e-04\n",
      "  ✓ New best: 0.4586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Train Loss 521.0 | Val Loss 153.8 | Acc 0.4661 | LR 5.0e-04\n",
      "  ✓ New best: 0.4661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Train Loss 511.2 | Val Loss 151.5 | Acc 0.4789 | LR 5.0e-04\n",
      "  ✓ New best: 0.4789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss 502.4 | Val Loss 148.1 | Acc 0.4804 | LR 5.0e-04\n",
      "  ✓ New best: 0.4804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss 497.3 | Val Loss 143.7 | Acc 0.4909 | LR 5.0e-04\n",
      "  ✓ New best: 0.4909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss 488.5 | Val Loss 141.7 | Acc 0.4861 | LR 5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss 485.8 | Val Loss 153.0 | Acc 0.4720 | LR 5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss 479.6 | Val Loss 140.6 | Acc 0.4907 | LR 5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss 475.4 | Val Loss 135.8 | Acc 0.4947 | LR 5.0e-04\n",
      "  ✓ New best: 0.4947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss 470.2 | Val Loss 132.5 | Acc 0.4954 | LR 5.0e-04\n",
      "  ✓ New best: 0.4954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss 467.2 | Val Loss 139.8 | Acc 0.4922 | LR 5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss 462.5 | Val Loss 129.7 | Acc 0.5096 | LR 5.0e-04\n",
      "  ✓ New best: 0.5096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss 459.1 | Val Loss 136.3 | Acc 0.4916 | LR 5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss 456.8 | Val Loss 134.1 | Acc 0.4983 | LR 5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss 456.8 | Val Loss 139.1 | Acc 0.4962 | LR 2.5e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss 434.4 | Val Loss 129.9 | Acc 0.5193 | LR 2.5e-04\n",
      "  ✓ New best: 0.5193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss 416.4 | Val Loss 126.2 | Acc 0.5184 | LR 2.5e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss 411.9 | Val Loss 133.1 | Acc 0.5157 | LR 2.5e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss 408.8 | Val Loss 126.8 | Acc 0.5248 | LR 2.5e-04\n",
      "  ✓ New best: 0.5248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss 407.1 | Val Loss 127.7 | Acc 0.5237 | LR 1.3e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss 396.0 | Val Loss 129.3 | Acc 0.5210 | LR 1.3e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss 387.2 | Val Loss 132.5 | Acc 0.5238 | LR 1.3e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss 386.1 | Val Loss 124.6 | Acc 0.5302 | LR 1.3e-04\n",
      "  ✓ New best: 0.5302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss 383.6 | Val Loss 123.7 | Acc 0.5381 | LR 1.3e-04\n",
      "  ✓ New best: 0.5381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Loss 381.9 | Val Loss 122.0 | Acc 0.5378 | LR 1.3e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train Loss 379.0 | Val Loss 121.5 | Acc 0.5402 | LR 1.3e-04\n",
      "  ✓ New best: 0.5402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Train Loss 376.6 | Val Loss 125.4 | Acc 0.5354 | LR 1.3e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Train Loss 374.6 | Val Loss 130.0 | Acc 0.5314 | LR 1.3e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Train Loss 376.9 | Val Loss 124.0 | Acc 0.5360 | LR 6.3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Train Loss 370.3 | Val Loss 124.2 | Acc 0.5360 | LR 6.3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Train Loss 366.1 | Val Loss 124.7 | Acc 0.5416 | LR 6.3e-05\n",
      "  ✓ New best: 0.5416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Train Loss 366.2 | Val Loss 124.4 | Acc 0.5384 | LR 3.1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Train Loss 360.8 | Val Loss 124.2 | Acc 0.5397 | LR 3.1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Train Loss 360.5 | Val Loss 126.6 | Acc 0.5398 | LR 3.1e-05\n",
      "Training complete. Best Avg Val Acc = 0.5416469308812588\n"
     ]
    }
   ],
   "source": [
    "#RECALL MODEL\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import WeightedRandomSampler, DataLoader\n",
    "from rdkit import RDLogger\n",
    "\n",
    "\n",
    "# 1) Count how often each potency label (0-5) appears anywhere in the training set\n",
    "class_freq = np.zeros(6, dtype=int)         # one slot per class\n",
    "for _, lbl_vec in train_ds.records:    # lbl_vec length = 59 (or 60) cell lines\n",
    "    labels  = np.asarray(lbl_vec, dtype=int)\n",
    "    present = labels[labels >= 0]           # drop -1 (missing) entries\n",
    "    class_freq += np.bincount(present, minlength=6)\n",
    "\n",
    "# 2) Inverse-√ frequency weights, normalised so their mean ≈ 1\n",
    "inv_sqrt = 1 / np.sqrt(class_freq + 1e-6)\n",
    "inv_sqrt = inv_sqrt / inv_sqrt.mean()\n",
    "\n",
    "# 3) Weight each molecule by the *average* weight of the labels it actually has\n",
    "sample_weights = []\n",
    "for _, lbl_vec in train_ds.records:\n",
    "    labels  = np.asarray(lbl_vec, dtype=int)\n",
    "    present = labels[labels >= 0]\n",
    "    sample_weights.append(float(inv_sqrt[present].mean()))\n",
    "\n",
    "# 4) Build a weighted sampler and the DataLoader\n",
    "sampler = WeightedRandomSampler(sample_weights,\n",
    "                                num_samples=len(sample_weights),\n",
    "                                replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_ds,\n",
    "                          batch_size=64,\n",
    "                          sampler=sampler,\n",
    "                          num_workers=4,\n",
    "                          pin_memory=True)\n",
    "\n",
    "val_loader   = DataLoader(val_ds,   batch_size=64,\n",
    "                          shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=64,\n",
    "                          shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# --- Training setup ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model  = MultiLineMLP5().to(device)\n",
    "\n",
    "# No class-weights here:\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=2)\n",
    "\n",
    "def full_val_accuracy(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = np.zeros(60); total = np.zeros(60)\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x).argmax(2)\n",
    "            mask = y != -1\n",
    "            correct += ((pred == y) & mask).sum(0).cpu().numpy()\n",
    "            total   += mask.sum(0).cpu().numpy()\n",
    "    accs = [c / t if t>0 else 0.0 for c, t in zip(correct, total)]\n",
    "    return float(np.nanmean(accs)), accs\n",
    "\n",
    "# --- Training loop ---\n",
    "best_acc = 0.0\n",
    "for epoch in range(1, 41):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch}\", leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits.view(-1,6), y.view(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # validation\n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            val_loss += criterion(\n",
    "                model(x).view(-1,6), y.view(-1)\n",
    "            ).item()\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "    avg_acc, _ = full_val_accuracy(model, val_loader, device)\n",
    "    print(f\"Epoch {epoch:02} | Train Loss {train_loss:.1f} \"\n",
    "          f\"| Val Loss {val_loss:.1f} | Acc {avg_acc:.4f} \"\n",
    "          f\"| LR {optimizer.param_groups[0]['lr']:.1e}\")\n",
    "\n",
    "    if avg_acc > best_acc:\n",
    "        best_acc = avg_acc\n",
    "        torch.save(model.state_dict(), \"best_resampled.pt\")\n",
    "        print(f\"  ✓ New best: {best_acc:.4f}\")\n",
    "\n",
    "print(\"Training complete. Best Avg Val Acc =\", best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be254f8f-a4d0-4a98-9f5d-660cf902ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def micro_precision_recall(model, loader, device, num_lines=59):\n",
    "    \"\"\"\n",
    "    Micro-averaged precision and recall across all cell lines and samples.\n",
    "    Returns: (precision_exact, recall_exact), (precision_within1, recall_within1)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            logits = model(x)[:, :num_lines]     # (B, 59, 6)\n",
    "            preds = logits.argmax(dim=2).cpu().numpy()   # (B, 59)\n",
    "            y     = y[:, :num_lines].cpu().numpy()        # (B, 59)\n",
    "\n",
    "            mask = (y != -1)\n",
    "            y_true_all.append(y[mask])\n",
    "            y_pred_all.append(preds[mask])\n",
    "\n",
    "    y_true = np.concatenate(y_true_all)\n",
    "    y_pred = np.concatenate(y_pred_all)\n",
    "\n",
    "    precision = []\n",
    "    recall    = []\n",
    "    precision1 = []\n",
    "    recall1    = []\n",
    "\n",
    "    for c in range(6):\n",
    "        tp  = np.sum((y_pred == c) & (y_true == c))\n",
    "        fp  = np.sum((y_pred == c) & (y_true != c))\n",
    "        fn  = np.sum((y_pred != c) & (y_true == c))\n",
    "\n",
    "        tp1 = np.sum((y_pred == c) & (np.abs(y_true - c) <= 1))\n",
    "        fp1 = np.sum((y_pred == c) & (np.abs(y_true - c) >  1))\n",
    "        fn1 = np.sum((y_pred != c) & (y_true == c) & (np.abs(y_pred - c) <= 1))\n",
    "\n",
    "        p  = tp  / (tp + fp) if (tp + fp) > 0 else np.nan\n",
    "        r  = tp  / (tp + fn) if (tp + fn) > 0 else np.nan\n",
    "        p1 = tp1 / (tp1 + fp1) if (tp1 + fp1) > 0 else np.nan\n",
    "        r1 = tp1 / (tp1 + fn1) if (tp1 + fn1) > 0 else np.nan\n",
    "\n",
    "        precision.append(p)\n",
    "        recall.append(r)\n",
    "        precision1.append(p1)\n",
    "        recall1.append(r1)\n",
    "\n",
    "    return np.array(precision), np.array(recall), np.array(precision1), np.array(recall1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5d2f290-23fc-4967-8a71-1285fb56187c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Class   Exact P      ±1 P   Exact R      ±1 R\n",
      "     0      70.2%      91.3%      62.2%      75.7%\n",
      "     1      48.7%      97.1%      49.9%      68.8%\n",
      "     2      48.4%      84.1%      51.8%      72.1%\n",
      "     3      35.4%      76.3%      42.8%      69.3%\n",
      "     4      30.5%      69.4%      34.8%      66.3%\n",
      "     5      37.3%      62.1%      44.1%      68.9%\n"
     ]
    }
   ],
   "source": [
    "prec, rec, prec1, rec1 = micro_precision_recall(model, val_loader, device)\n",
    "\n",
    "headers = [\"Exact P\", \"±1 P\", \"Exact R\", \"±1 R\"]\n",
    "print(f\"{'Class':>6}  {headers[0]:>8}  {headers[1]:>8}  \"\n",
    "      f\"{headers[2]:>8}  {headers[3]:>8}\")\n",
    "for c in range(6):\n",
    "    print(f\"{c:>6}  {prec[c]*100:8.1f}%  {prec1[c]*100:8.1f}%  \"\n",
    "          f\"{rec[c]*100:8.1f}%  {rec1[c]*100:8.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b716d26b-ead0-47db-a499-c026de6ae96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint from epoch 28\n",
      "Validation accuracy at save time: 0.5446336553684783\n",
      "Validation accuracy after reload: 0.5453763468470059\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. Set up model as usual\n",
    "model = MultiLineMLP5(hidden_dims=[1024,1024,512,512,256], p_drop=0.3).to(device)\n",
    "\n",
    "# 2. Load the checkpoint\n",
    "ckpt = torch.load(\"best_resampled.pt\", map_location=device)\n",
    "\n",
    "# 3. Restore model state\n",
    "model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "# 4. (Optional) check epoch / history\n",
    "print(f\"Checkpoint from epoch {ckpt['epoch']}\")\n",
    "if \"history\" in ckpt:\n",
    "    print(\"Validation accuracy at save time:\", ckpt[\"history\"][\"val_acc\"][-1])\n",
    "\n",
    "# 5. Run a quick accuracy check\n",
    "def evaluate(loader):\n",
    "    correct = total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            p = model(x).argmax(2)\n",
    "            m = y != -1\n",
    "            correct += ((p == y) & m).sum().item()\n",
    "            total   += m.sum().item()\n",
    "    return correct / total if total else 0.0\n",
    "\n",
    "val_acc = evaluate(val_loader)\n",
    "print(\"Validation accuracy after reload:\", val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b54720c-5370-4960-8bcb-4e34749a4363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
